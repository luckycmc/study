server.c 服务端代码:
    socket()
    bind()
    listen()
    accept()
    read()
    write()
    close()

clent.c
     socket()
     connect();
     write();
     read();
     close();


//file: net/core/request_sock.c  //对应的 文件代码

int reqsk_queue_alloc(struct request_sock_queue *queue,
     unsigned int nr_table_entries)
{
            size_t lopt_size = sizeof(struct listen_sock);
            struct listen_sock *lopt;

            //计算半连接队列的长度
            nr_table_entries = min_t(u32, nr_table_entries, sysctl_max_syn_backlog);
            nr_table_entries = ......

            //为半连接队列申请内存
            lopt_size += nr_table_entries * sizeof(struct request_sock *);
            if (lopt_size > PAGE_SIZE)
            lopt = vzalloc(lopt_size);
            else
            lopt = kzalloc(lopt_size, GFP_KERNEL);

            //全连接队列头初始化
            queue->rskq_accept_head = NULL;  //链表

            //半连接队列设置
            lopt->nr_table_entries = nr_table_entries;
            queue->listen_opt = lopt;
            ......
}

server listen 的主要作用:
    在服务器 listen 的时候，主要是进行了全/半连接队列的长度限制计算，
    以及相关的内存申请和初始化。全/连接队列初始化了以后才可以相应来自客户端的握手请求

client connect()
   
    客户端通过调用 connect 来发起连接。在 connect 系统调用中会进入到内核源码的 tcp_v4_connect。
    //file: net/ipv4/tcp_ipv4.c
    int tcp_v4_connect(struct sock *sk, struct sockaddr *uaddr, int addr_len)
    {
        //设置 socket 状态为 TCP_SYN_SENT
        tcp_set_state(sk, TCP_SYN_SENT);

        //动态选择一个端口
        err = inet_hash_connect(&tcp_death_row, sk);

        //函数用来根据 sk 中的信息，构建一个完成的 syn 报文，并将它发送出去。
        err = tcp_connect(sk);  //构建相应的报文发送出去
    }

     在这里将完成把 socket 状态设置为 TCP_SYN_SENT。再通过 inet_hash_connect 来动态地选择一个可用的端口后
     进入到 tcp_connect 中。

    /file:net/ipv4/tcp_output.c
    int tcp_connect(struct sock *sk)
    {
        tcp_connect_init(sk);  //连接初始化

        //申请 skb 并构造为一个 SYN 包
        ......

        //添加到发送队列 sk_write_queue 上
        tcp_connect_queue_skb(sk, buff);

        //实际发出 syn
        err = tp->fastopen_req ? tcp_send_syn_data(sk, buff) :
            tcp_transmit_skb(sk, buff, 1, sk->sk_allocation);

        //启动重传定时器
        inet_csk_reset_xmit_timer(sk, ICSK_TIME_RETRANS,
            inet_csk(sk)->icsk_rto, TCP_RTO_MAX);
    }

    在 tcp_connect 申请和构造 SYN 包，然后将其发出。同时还启动了一个重传定时器，
    该定时器的作用是等到一定时间后收不到服务器的反馈的时候来开启重传。

    总结一下，客户端在 connect 的时候，把本地 socket 状态设置成了 TCP_SYN_SENT，
    选了一个可用的端口，接着发出 SYN 握手请求并启动重传定时器。


    三、服务器响应 SYN
        
        在服务器端，所有的 TCP 包（包括客户端发来的 SYN 握手请求）都经过网卡、软中断，进入到 tcp_v4_rcv。
        在该函数中根据网络包（skb）TCP 头信息中的目的 IP 信息查到当前在 listen 的 socket。然后继续进入 
        tcp_v4_do_rcv 处理握手过程。

        /file: net/ipv4/tcp_ipv4.c
        int tcp_v4_conn_request(struct sock *sk, struct sk_buff *skb)
        {
                //看看半连接队列是否满了
                if (inet_csk_reqsk_queue_is_full(sk) && !isn) {
                want_cookie = tcp_syn_flood_action(sk, skb, "TCP");
                if (!want_cookie)
                goto drop;
                }

                //在全连接队列满的情况下，如果有 young_ack，那么直接丢
                if (sk_acceptq_is_full(sk) && inet_csk_reqsk_queue_young(sk) > 1) {
                NET_INC_STATS_BH(sock_net(sk), LINUX_MIB_LISTENOVERFLOWS);
                goto drop;
                }
                ...
                //分配 request_sock 内核对象
                req = inet_reqsk_alloc(&tcp_request_sock_ops);

                //构造 syn+ack 包
                skb_synack = tcp_make_synack(sk, dst, req,
                fastopen_cookie_present(&valid_foc) ? &valid_foc : NULL);

                if (likely(!do_fastopen)) {
                //发送 syn + ack 响应
                err = ip_build_and_send_pkt(skb_synack, sk, ireq->loc_addr,
                    ireq->rmt_addr, ireq->opt);

                //添加到半连接队列，并开启计时器
                inet_csk_reqsk_queue_hash_add(sk, req, TCP_TIMEOUT_INIT);
                }else ...
        }
    
       在这里首先判断半连接队列是否满了，如果满了的话进入 tcp_syn_flood_action 去判断是否开启了 tcp_syncookies 内核参数。
       如果队列满，且未开启 tcp_syncookies，那么该握手包将直接被丢弃！！

       接着还要判断全连接队列是否满。因为全连接队列满也会导致握手异常的，那干脆就在第一次握手的时候也判断了。
       如果全连接队列满了，且有 young_ack 的话，那么同样也是直接丢弃。

       总结一下，服务器响应 ack 是主要工作是判断下接收队列是否满了，满的话可能会丢弃该请求，否则发出 synack。
       申请 request_sock 添加到半连接队列中，同时启动定时器。


       四、客户端响应 SYNACK
          客户端收到服务器端发来的 synack 包的时候，也会进入到 tcp_rcv_state_process 函数中来。不过由于自身 socket 
          的状态是 TCP_SYN_SENT，所以会进入到另一个不同的分支中去。

          /file:net/ipv4/tcp_input.c
            //除了 ESTABLISHED 和 TIME_WAIT，其他状态下的 TCP 处理都走这里
            int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb,
                const struct tcphdr *th, unsigned int len)
            {
                switch (sk->sk_state) {
                //服务器收到第一个ACK包
                case TCP_LISTEN:
                ...
                //客户端第二次握手处理 
                case TCP_SYN_SENT:
                //处理 synack 包
                queued = tcp_rcv_synsent_state_process(sk, skb, th, len);
                ...
                return 0;
            }
        
        //file:net/ipv4/tcp_input.c
        static int tcp_rcv_synsent_state_process(struct sock *sk, struct sk_buff *skb,
            const struct tcphdr *th, unsigned int len)
        {
            ...

            tcp_ack(sk, skb, FLAG_SLOWPATH);

            //连接建立完成 
            tcp_finish_connect(sk, skb);

            if (sk->sk_write_pending ||
            icsk->icsk_accept_queue.rskq_defer_accept ||
            icsk->icsk_ack.pingpong)
            //延迟确认...
            else {
            tcp_send_ack(sk);
            }
        } 

        //file: net/ipv4/tcp_input.c  tcp完成客户端；连接
        void tcp_finish_connect(struct sock *sk, struct sk_buff *skb)
        {
            //修改 socket 状态
            tcp_set_state(sk, TCP_ESTABLISHED);

            //初始化拥塞控制
            tcp_init_congestion_control(sk);
            ...

            //保活计时器打开
            if (sock_flag(sk, SOCK_KEEPOPEN))
            inet_csk_reset_keepalive_timer(sk, keepalive_time_when(tp));
        }

        客户端修改自己的 socket 状态为 ESTABLISHED，接着打开 TCP 的保活计时器。
        /file:net/ipv4/tcp_output.c
        void tcp_send_ack(struct sock *sk)
        {
            //申请和构造 ack 包  构建对应的数据包
            buff = alloc_skb(MAX_TCP_HEADER, sk_gfp_atomic(sk, GFP_ATOMIC));
            ...

            //发送出去  
            tcp_transmit_skb(sk, buff, 0, sk_gfp_atomic(sk, GFP_ATOMIC));
        }

        客户端响应来自服务器端的 synack 时清除了 connect 时设置的重传定时器，把当前 socket 状态设置为 ESTABLISHED，
        开启保活计时器后发出第三次握手的 ack 确认。

    五、服务器响应 ACK 

        服务器响应第三次握手的 ack 时同样会进入到 tcp_v4_do_rcv
        5.1 创建子 socket
        5.2 删除半连接队列
           把连接请求块从半连接队列中删除

        5.3 添加全连接队列
            接着添加到全连接队列里边来。

        5.4 设置连接为 ESTABLISHED
        总结:
            服务器响应第三次握手 ack 所做的工作是把当前半连接对象删除，创建了新的 sock 后加入到全连接队列中，
            最后将新连接状态设置为 ESTABLISHED。

    六、服务器 accept

        /file: net/ipv4/inet_connection_sock.c
        struct sock *inet_csk_accept(struct sock *sk, int flags, int *err)
        {
            //从全连接队列中获取
            struct request_sock_queue *queue = &icsk->icsk_accept_queue;
            req = reqsk_queue_remove(queue);

            newsk = req->sk;
            return newsk;
        }
        reqsk_queue_remove 这个操作很简单，就是从全连接队列的链表里获取出第一个元素返回就行了。
        //file:include/net/request_sock.h
        static inline struct request_sock *reqsk_queue_remove(struct request_sock_queue *queue)
        {
            struct request_sock *req = queue->rskq_accept_head;

            queue->rskq_accept_head = req->dl_next;
            if (queue->rskq_accept_head == NULL)
            queue->rskq_accept_tail = NULL;

            return req;
        }
        所以，accept 的重点工作就是从已经建立好的全连接队列中取出一个返回给用户进程。


总结以上步骤:

       1. 服务器 listen 时，计算了全/半连接队列的长度，还申请了相关内存并初始化。
       2. 客户端 connect 时，把本地 socket 状态设置成了 TCP_SYN_SENT，选则一个可用的端口，
           发出 SYN 握手请求并启动重传定时器。
       3. 服务器响应 ack 时，会判断下接收队列是否满了，满的话可能会丢弃该请求。否则发出 synack，
           申请 request_sock 添加到半连接队列中，同时启动定时器。
       4. 客户端响应 synack 时，清除了 connect 时设置的重传定时器，把当前 socket 状态设置为 ESTABLISHED，
           开启保活计时器后发出第三次握手的 ack 确认。
       5. 服务器响应 ack 时，把对应半连接对象删除，创建了新的 sock 后加入到全连接队列中，
           最后将新连接状态设置为 ESTABLISHED。
        6. accept 从已经建立好的全连接队列中取出一个返回给用户进程。